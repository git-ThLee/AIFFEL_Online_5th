{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98b268e",
   "metadata": {},
   "source": [
    "# STEP 1. NSMC 데이터 분석 및 Huggingface dataset 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "843ead1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (/aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9df31644e1a47cabf4dd037e063b508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 150000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nsmc\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "86e69064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아 더빙.. 진짜 짜증나네요 목소리'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['document'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c6381d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 54620 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44544 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 53581 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 49828 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 53944 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 44600 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 48516 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:240: RuntimeWarning: Glyph 54252 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 54620 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44544 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 53581 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 49828 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 53944 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 44600 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 51060 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 48516 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/opt/conda/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:203: RuntimeWarning: Glyph 54252 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train 데이터셋에서 'document' 열 추출\n",
    "documents = dataset[\"train\"][\"document\"]\n",
    "\n",
    "# 한글 텍스트의 길이 측정\n",
    "text_lengths = [len(text) for text in documents]\n",
    "\n",
    "# 길이 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(text_lengths, bins=50, color='blue', alpha=0.7)\n",
    "plt.title('한글 텍스트 길이 분포')\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "33f1d575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75173\n",
      "74827\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][\"label\"].count(0))\n",
    "print(dataset[\"train\"][\"label\"].count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bd6a3",
   "metadata": {},
   "source": [
    "# STEP 2. klue/bert-base model 및 tokenizer 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a358018b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/vocab.txt from cache at /aiffel/.cache/huggingface/transformers/1a36e69d48a008e522b75e43693002ffc8b6e6df72de7c53412c23466ec165eb.085110015ec67fc02ad067f712a7c83aafefaf31586a3361dd800bcac635b456\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/tokenizer.json from cache at /aiffel/.cache/huggingface/transformers/310a974e892b181d75eed58b545cc0592d066ae4ef35cc760ea92e9b0bf65b3b.74f7933572f937b11a02b2cfb4e88a024059be36c84f53241b85b1fec49e21f7\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/special_tokens_map.json from cache at /aiffel/.cache/huggingface/transformers/aeaaa3afd086a040be912f92ffe7b5f85008b744624f4517c4216bcc32b51cf0.054ece8d16bd524c8a00f0e8a976c00d5de22a755ffb79e353ee2954d9289e26\n",
      "loading file https://huggingface.co/klue/bert-base/resolve/main/tokenizer_config.json from cache at /aiffel/.cache/huggingface/transformers/f8f71eb411bb03f57b455cfb1b4e04ae124201312e67a3ad66e0a92d0c228325.78871951edcb66032caa0a9628d77b3557c23616c653dacdb7a1a8f33011a843\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = 'klue/bert-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d25fc",
   "metadata": {},
   "source": [
    "# STEP 3. 위에서 불러온 tokenizer으로 데이터셋을 전처리하고, model 학습 진행해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d10082",
   "metadata": {},
   "source": [
    "# STEP 4. Fine-tuning을 통하여 모델 성능(accuarcy) 향상시키기\n",
    "\n",
    "- 데이터 전처리, TrainingArguments 등을 조정하여 모델의 정확도를 90% 이상으로 끌어올려봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7c3f338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-12f6fa2c5c3ecf71.arrow\n",
      "Loading cached processed dataset at /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-d97d4642b1141e81.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'document', 'id', 'input_ids', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'document', 'id', 'input_ids', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(data):\n",
    "    return tokenizer(\n",
    "        data['document'],\n",
    "        truncation = True,\n",
    "        padding = 'max_length',\n",
    "        max_length = 40, # 140\n",
    "        return_token_type_ids = False,\n",
    "        )\n",
    "dataset = dataset.map(transform, batched=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6afd0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 100개만 사용 \n",
    "# data_cnt = 6000\n",
    "# dateset_100 = dataset['train'].select(range(data_cnt))\n",
    "# dataset['train'] = dateset_100\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "60ee3edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰 길이 : paading 포함\n",
    "len(dateset_100['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0ab2f38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-1ee25a1d2486862c.arrow\n",
      "Loading cached shuffled indices for dataset at /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-1ee25a1d2486862c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "30000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# train val 나누기\n",
    "train_dataset = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train'])*0.8)))\n",
    "valid_dataset = dataset['train'].shuffle(seed=42).select(range(int(len(dataset['train'])*0.8),len(dataset['train'])))\n",
    "\n",
    "# test\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "764bf4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "output_dir = os.getenv('HOME')+'/aiffel/huggingface/checkpoint_alldata_maxlen40'\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir,                                         # output이 저장될 경로\n",
    "    evaluation_strategy=\"epoch\",           #evaluation하는 빈도\n",
    "    learning_rate = 2e-5,                         #learning_rate\n",
    "    per_device_train_batch_size = 4,   # 각 device 당 batch size\n",
    "    per_device_eval_batch_size = 4,    # evaluation 시에 batch size\n",
    "    num_train_epochs = 1,                     # train 시킬 총 epochs\n",
    "    weight_decay = 0.01,                        # weight decay\n",
    "    save_steps = 1000,  # 원하는 체크포인트 저장 간격 설정 (예: 100, 200 등)\n",
    "    save_total_limit=5,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "be81529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric('glue', 'mrpc')\n",
    "\n",
    "def compute_metrics(eval_pred):    \n",
    "    predictions,labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8ad5ab14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6006"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "89a9e005",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 120000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 45:20, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.397361</td>\n",
       "      <td>0.897433</td>\n",
       "      <td>0.897238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-17000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-19000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-19000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-19000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-20000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-20000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-21000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-21000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-21000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-22000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-22000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-23000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-23000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-23000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-24000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-24000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-25000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-25000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-25000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-26000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-26000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-26000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-27000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-27000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-27000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-28000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-28000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-28000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-29000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-29000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-29000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-30000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-30000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-30000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoint_alldata_maxlen40/checkpoint-25000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30000, training_loss=0.43557698415120444, metrics={'train_runtime': 2720.7858, 'train_samples_per_second': 44.105, 'train_steps_per_second': 11.026, 'total_flos': 2466666144000000.0, 'train_loss': 0.43557698415120444, 'epoch': 1.0})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,           # 학습시킬 model\n",
    "    args=training_arguments,           # TrainingArguments을 통해 설정한 arguments\n",
    "    train_dataset = train_dataset,    # training dataset\n",
    "    eval_dataset = valid_dataset,       # evaluation dataset\n",
    "    \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6d9b83a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 02:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3988664746284485,\n",
       " 'eval_accuracy': 0.89784,\n",
       " 'eval_f1': 0.8984331504016543,\n",
       " 'eval_runtime': 168.4364,\n",
       " 'eval_samples_per_second': 296.848,\n",
       " 'eval_steps_per_second': 74.212,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d076e9",
   "metadata": {},
   "source": [
    "- train : 30000, max_len : 140, 학습시간 : 110분\n",
    "    - 근데 왜 학습할 땐, 30000 이라고 뜨지? : per_device_train_batch_size 영향인듯 \n",
    "\n",
    "|Epoch|\tTraining Loss|\tValidation Loss\t|Accuracy|\tF1|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|1|\t0.399100|\t0.387210|\t🧷`0.901000`🧷|\t0.900974|\n",
    "\n",
    "{'eval_loss': 0.39205992221832275,    \n",
    " 'eval_accuracy': `0.89954`,  \n",
    " \n",
    " 'eval_f1': 0.9002363502750799,    \n",
    " 'eval_runtime': 456.5871,  \n",
    " 'eval_samples_per_second': 109.508,  \n",
    " 'eval_steps_per_second': 27.377,  \n",
    " 'epoch': 1.0}  \n",
    " \n",
    "---\n",
    "\n",
    "- train : 30000, max_len : 40, 학습시간 : 43분\n",
    "\n",
    "|Epoch|\tTraining Loss|\tValidation Loss\t|Accuracy|\tF1|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|1|\t0.394100|\t0.397361|\t0.897433|\t0.897238|\n",
    "\n",
    "{'eval_loss': 0.3988664746284485,  \n",
    " 'eval_accuracy': `0.89784`,  \n",
    " \n",
    " 'eval_f1': 0.8984331504016543,  \n",
    " 'eval_runtime': 168.4364,  \n",
    " 'eval_samples_per_second': 296.848,  \n",
    " 'eval_steps_per_second': 74.212,  \n",
    " 'epoch': 1.0}  \n",
    "\n",
    "---\n",
    "\n",
    "- data : 6000개, Max_length : 512 , 학습시간 : 44분\n",
    "\n",
    "|Epoch|\tTraining Loss|\tValidation Loss\t|Accuracy|\tF1|\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|1|\t0.404800|\t0.429618|\t0.881833|\t0.880860|\n",
    "\n",
    "{'eval_loss': 0.4197678864002228,  \n",
    " 'eval_accuracy': 0.87954,  \n",
    " 'eval_f1': 0.8789565706706325,  \n",
    " 'eval_runtime': 1700.6425,  \n",
    " 'eval_samples_per_second': 29.401,  \n",
    " 'eval_steps_per_second': 7.35,  \n",
    " 'epoch': 1.0}  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61f876",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "### 1. document 데이터의 텍스트 길이가 140 이하임을 확인하고, 불필요한 max_len을 줄였더니 성능이 향상함\n",
    "\n",
    "### 2. 데이터 개수에 따른 성능이 차이남 (많을 수록 좋음), 단 학습 속도가 지나치게 느려져서 합의점 필요\n",
    "\n",
    "### 3. max_len 140 vs 40 비교 결과, 성능 면에서는 140이 좋지만 미세한 차이임. 즉, 학습 속도가 유리한 40을 위주로 STEP 5을 진행함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49169f",
   "metadata": {},
   "source": [
    "# STEP 5. Bucketing을 적용하여 학습시키고, STEP 4의 결과와의 비교\n",
    "\n",
    "```\n",
    "아래 링크를 바탕으로 bucketing과 dynamic padding이 무엇인지 알아보고, 이들을 적용하여 model을 학습시킵니다.\n",
    "\n",
    "Data Collator\n",
    "\n",
    "Trainer.TrainingArguments 의 group_by_length\n",
    "\n",
    "STEP 4에 학습한 결과와 bucketing을 적용하여 학습시킨 결과를 비교해보고, 모델 성능 향상과 훈련 시간 두 가지 측면에서 각각 어떤 이점이 있는지 비교해봅시다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442c7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "63bd8943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "output_dir = os.getenv('HOME')+'/aiffel/huggingface/checkpoints_bucketing'\n",
    "\n",
    "# 데이터 콜레이터\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir,                                         # output이 저장될 경로\n",
    "    evaluation_strategy=\"epoch\",           #evaluation하는 빈도\n",
    "    learning_rate = 2e-5,                         #learning_rate\n",
    "    per_device_train_batch_size = 4,   # 각 device 당 batch size\n",
    "    per_device_eval_batch_size = 4,    # evaluation 시에 batch size\n",
    "    num_train_epochs = 1,                     # train 시킬 총 epochs\n",
    "    weight_decay = 0.01,                        # weight decay\n",
    "    save_steps = 1000,  # 원하는 체크포인트 저장 간격 설정 (예: 100, 200 등)\n",
    "    save_total_limit=5,\n",
    "    \n",
    "    group_by_length=True,  # Bucketing 활성화\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d8b58ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 120000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 30000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30000' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30000/30000 44:54, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.397512</td>\n",
       "      <td>0.896667</td>\n",
       "      <td>0.896777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-17000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-19000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-19000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-19000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-20000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-20000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-21000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-21000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-21000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-22000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-22000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-23000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-23000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-23000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-24000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-24000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-25000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-25000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-25000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-26000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-26000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-26000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-27000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-27000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-27000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-28000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-28000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-28000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-29000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-29000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-29000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-30000\n",
      "Configuration saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-30000/config.json\n",
      "Model weights saved in /aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-30000/pytorch_model.bin\n",
      "Deleting older checkpoint [/aiffel/aiffel/huggingface/checkpoints_bucketing/checkpoint-25000] due to args.save_total_limit\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 30000\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=30000, training_loss=0.4382775217692057, metrics={'train_runtime': 2695.1836, 'train_samples_per_second': 44.524, 'train_steps_per_second': 11.131, 'total_flos': 2466666144000000.0, 'train_loss': 0.4382775217692057, 'epoch': 1.0})"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,           # 학습시킬 model\n",
    "    args=training_arguments,           # TrainingArguments을 통해 설정한 arguments\n",
    "    train_dataset = train_dataset,    # training dataset\n",
    "    eval_dataset = valid_dataset,       # evaluation dataset\n",
    "    \n",
    "    data_collator=data_collator,\n",
    "    \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "769039c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 02:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3995944857597351,\n",
       " 'eval_accuracy': 0.89736,\n",
       " 'eval_f1': 0.8981584378472773,\n",
       " 'eval_runtime': 168.1401,\n",
       " 'eval_samples_per_second': 297.371,\n",
       " 'eval_steps_per_second': 74.343,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c2b10",
   "metadata": {},
   "source": [
    "## STEP 5 결론\n",
    "\n",
    "\n",
    "- 공동 조건 : train : 30000, max_len : 40, \n",
    "    - 일반 학습\n",
    "        - 학습시간 : 43분, Valid Acc : 0.897433, Valid F1 : 0.897238, Eval Acc : 0.89784, Eval F1 : 0.898433\n",
    "    - bucketing\n",
    "        - 학습시간 : 43분, Valid Acc : 0.896667, Valid F1 : 0.896777, Eval Acc : 0.89736, Eval F1 : 0.898158\n",
    "        \n",
    "        \n",
    "        \n",
    "### 1. Bucketing + DataCollatorWithPadding을 사용하면 성능이 떨어지나, 큰 차이가 없다. \n",
    "### 이유 : 시퀀스 길이 분포와 max_length 설정이 잘 맞아 떨어져서 성능에 큰 차이가 없는 것으로 보인다. 아무래도 max_len이 40으로 매우 적은 시퀀스 길이 분포를 유지하며, 대부분의 데이터가 시퀀스 길이가 비슷함에 따라 성능에 큰 차이가 없어 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59943c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
